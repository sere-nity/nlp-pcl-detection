{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ac641ce",
   "metadata": {
    "id": "H08esTFOYO99"
   },
   "source": [
    "# Main imports and code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac462fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EnHQoayhBYlm",
    "outputId": "7d7ee056-47c1-41b0-b3cc-fe556bc87027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 24 11:47:18 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 591.86                 Driver Version: 591.86         CUDA Version: 13.1     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060      WDDM  |   00000000:06:00.0  On |                  N/A |\n",
      "|  0%   44C    P8             11W /  170W |     938MiB /  12288MiB |     85%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A             956    C+G   ...64__8wekyb3d8bbwe\\Copilot.exe      N/A      |\n",
      "|    0   N/A  N/A            2340    C+G   ...ntrolPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A            2388    C+G   ...grams\\LM Studio\\LM Studio.exe      N/A      |\n",
      "|    0   N/A  N/A            3772    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A            5696    C+G   ...em32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A            6012    C+G   ...al\\Programs\\Notion\\Notion.exe      N/A      |\n",
      "|    0   N/A  N/A            6828    C+G   ...al\\Programs\\cursor\\Cursor.exe      N/A      |\n",
      "|    0   N/A  N/A            9816    C+G   ...mon\\Client\\v1.6.0\\rsAppUI.exe      N/A      |\n",
      "|    0   N/A  N/A           10020    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           10504    C+G   ...2txyewy\\CrossDeviceResume.exe      N/A      |\n",
      "|    0   N/A  N/A           13036    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A           13044    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           15012    C+G   ....0.3800.70\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           16988    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           17664    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           19120    C+G   ....2_x64__ttt1ap7aakyb4\\Arc.exe      N/A      |\n",
      "|    0   N/A  N/A           20256    C+G   ...n\\AdobeNotificationClient.exe      N/A      |\n",
      "|    0   N/A  N/A           20508    C+G   ...yb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A           20828    C+G   ...erLink\\YouCam365\\YouCam10.exe      N/A      |\n",
      "|    0   N/A  N/A           21256    C+G   ...crosoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           21348    C+G   ...crosoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           24072    C+G   ...1g1gvanyjgm\\WhatsApp.Root.exe      N/A      |\n",
      "|    0   N/A  N/A           24112      C   ...grams\\LM Studio\\LM Studio.exe      N/A      |\n",
      "|    0   N/A  N/A           24320    C+G   ....0.3800.70\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           27560      C   ...s\\Python\\Python311\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           29044    C+G   ....2_x64__ttt1ap7aakyb4\\Arc.exe      N/A      |\n",
      "|    0   N/A  N/A           29172    C+G   ....2_x64__ttt1ap7aakyb4\\Arc.exe      N/A      |\n",
      "|    0   N/A  N/A           30672    C+G   ...8wekyb3d8bbwe\\XboxPcAppFT.exe      N/A      |\n",
      "|    0   N/A  N/A           32056    C+G   ...indows\\System32\\ShellHost.exe      N/A      |\n",
      "|    0   N/A  N/A           33920    C+G   ...cord\\app-1.0.9225\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A           39208    C+G   ...indows\\System32\\ShellHost.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# check which gpus we're using\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "771deef4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hYhFR7nSYOjG",
    "outputId": "66b49da3-0dfc-45a7-bf39-89926e0442f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: simpletransformers in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (0.70.5)\n",
      "Requirement already satisfied: numpy in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from simpletransformers) (2.4.2)\n",
      "Requirement already satisfied: requests in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from simpletransformers) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.47.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from simpletransformers) (4.67.3)\n",
      "Requirement already satisfied: regex in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from simpletransformers) (2026.2.19)\n",
      "Requirement already satisfied: transformers>=4.31.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from simpletransformers) (4.35.2)\n",
      "Requirement already satisfied: datasets in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from simpletransformers) (4.5.0)\n",
      "Requirement already satisfied: scipy in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from simpletransformers) (1.17.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from simpletransformers) (1.8.0)\n",
      "Requirement already satisfied: seqeval in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from simpletransformers) (1.2.2)\n",
      "Requirement already satisfied: tensorboard in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from simpletransformers) (2.20.0)\n",
      "Requirement already satisfied: tensorboardx in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from simpletransformers) (2.6.4)\n",
      "Requirement already satisfied: pandas in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from simpletransformers) (2.3.3)\n",
      "Requirement already satisfied: tokenizers in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from simpletransformers) (0.15.2)\n",
      "Requirement already satisfied: wandb>=0.10.32 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from simpletransformers) (0.25.0)\n",
      "Requirement already satisfied: streamlit in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from simpletransformers) (1.54.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from simpletransformers) (0.2.1)\n",
      "Requirement already satisfied: colorama in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from tqdm>=4.47.0->simpletransformers) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from transformers>=4.31.0->simpletransformers) (3.24.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from transformers>=4.31.0->simpletransformers) (0.36.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from transformers>=4.31.0->simpletransformers) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from transformers>=4.31.0->simpletransformers) (6.0.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from transformers>=4.31.0->simpletransformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.31.0->simpletransformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.31.0->simpletransformers) (4.15.0)\n",
      "Requirement already satisfied: click>=8.0.1 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from wandb>=0.10.32->simpletransformers) (8.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from wandb>=0.10.32->simpletransformers) (3.1.46)\n",
      "Requirement already satisfied: platformdirs in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from wandb>=0.10.32->simpletransformers) (4.9.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from wandb>=0.10.32->simpletransformers) (6.33.5)\n",
      "Requirement already satisfied: pydantic<3 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from wandb>=0.10.32->simpletransformers) (2.12.5)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from wandb>=0.10.32->simpletransformers) (2.53.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from pydantic<3->wandb>=0.10.32->simpletransformers) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from pydantic<3->wandb>=0.10.32->simpletransformers) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from pydantic<3->wandb>=0.10.32->simpletransformers) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from requests->simpletransformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from requests->simpletransformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from requests->simpletransformers) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from requests->simpletransformers) (2026.1.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (5.0.2)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from datasets->simpletransformers) (23.0.1)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from datasets->simpletransformers) (0.4.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from datasets->simpletransformers) (0.28.1)\n",
      "Requirement already satisfied: xxhash in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from datasets->simpletransformers) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from datasets->simpletransformers) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->simpletransformers) (3.13.3)\n",
      "Requirement already satisfied: anyio in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from httpx<1.0.0->datasets->simpletransformers) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from httpx<1.0.0->datasets->simpletransformers) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets->simpletransformers) (0.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->simpletransformers) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->simpletransformers) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->simpletransformers) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->simpletransformers) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->simpletransformers) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->simpletransformers) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->simpletransformers) (1.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from pandas->simpletransformers) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from pandas->simpletransformers) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from pandas->simpletransformers) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from python-dateutil>=2.8.2->pandas->simpletransformers) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from scikit-learn->simpletransformers) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from scikit-learn->simpletransformers) (3.6.0)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from streamlit->simpletransformers) (6.0.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from streamlit->simpletransformers) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=5.5 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from streamlit->simpletransformers) (6.2.6)\n",
      "Requirement already satisfied: pillow<13,>=7.1.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from streamlit->simpletransformers) (12.1.1)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from streamlit->simpletransformers) (0.9.1)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from streamlit->simpletransformers) (9.1.4)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from streamlit->simpletransformers) (0.10.2)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from streamlit->simpletransformers) (6.5.4)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from streamlit->simpletransformers) (6.0.0)\n",
      "Requirement already satisfied: jinja2 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->simpletransformers) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->simpletransformers) (4.26.0)\n",
      "Requirement already satisfied: narwhals>=1.27.1 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->simpletransformers) (2.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->simpletransformers) (3.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->simpletransformers) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->simpletransformers) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->simpletransformers) (0.30.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from tensorboard->simpletransformers) (2.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from tensorboard->simpletransformers) (1.78.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from tensorboard->simpletransformers) (3.10.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from tensorboard->simpletransformers) (65.5.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from tensorboard->simpletransformers) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from tensorboard->simpletransformers) (3.1.6)\n",
      "Requirement already satisfied: tensorboardx in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (2.6.4)\n",
      "Requirement already satisfied: numpy in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from tensorboardx) (2.4.2)\n",
      "Requirement already satisfied: packaging in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from tensorboardx) (26.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages (from tensorboardx) (6.33.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install simpletransformers\n",
    "!pip install tensorboardx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d662010",
   "metadata": {
    "id": "RJC8wj73Zd_p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs, MultiLabelClassificationModel, MultiLabelClassificationArgs\n",
    "from urllib import request\n",
    "import pandas as pd\n",
    "import logging\n",
    "import torch\n",
    "from collections import Counter\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79063984",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bsX3b7ZNYVZe",
    "outputId": "025d4151-b814-4f05-ca7b-1bc03cb1fb6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available?  True\n"
     ]
    }
   ],
   "source": [
    "# prepare logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# check gpu\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "print('Cuda available? ',cuda_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34bf8abe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HpRLLRzkTwdL",
    "outputId": "4a3bc1e7-423d-413a-8e27-3bdf15205e8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "# Use PyTorch for GPU check (same backend as simpletransformers). TensorFlow often\n",
    "# doesn't see the GPU on Windows (CPU-only install or CUDA mismatch).\n",
    "if cuda_available:\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    print('Found GPU: {}'.format(device_name))\n",
    "else:\n",
    "    print('No GPU found; training will use CPU (slower).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d6f2ce",
   "metadata": {
    "id": "BMQDATlOZHxu"
   },
   "source": [
    "# Fetch Don't Patronize Me! data manager module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2416fe76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UW903YxwThrH",
    "outputId": "70da8af3-9a5d-4385-c082-99d1cac5062c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching https://raw.githubusercontent.com/Perez-AlmendrosC/dontpatronizeme/master/semeval-2022/dont_patronize_me.py\n"
     ]
    }
   ],
   "source": [
    "module_url = f\"https://raw.githubusercontent.com/Perez-AlmendrosC/dontpatronizeme/master/semeval-2022/dont_patronize_me.py\"\n",
    "module_name = module_url.split('/')[-1]\n",
    "print(f'Fetching {module_url}')\n",
    "#with open(\"file_1.txt\") as f1, open(\"file_2.txt\") as f2\n",
    "with request.urlopen(module_url) as f, open(module_name,'w') as outf:\n",
    "  a = f.read()\n",
    "  outf.write(a.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57393b64",
   "metadata": {
    "id": "PRxm0179aqzw"
   },
   "outputs": [],
   "source": [
    "# helper function to save predictions to an output file\n",
    "def labels2file(p, outf_path):\n",
    "\twith open(outf_path,'w') as outf:\n",
    "\t\tfor pi in p:\n",
    "\t\t\toutf.write(','.join([str(k) for k in pi])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "441fb058",
   "metadata": {
    "id": "gcDThFWVBxGb"
   },
   "outputs": [],
   "source": [
    "from dont_patronize_me import DontPatronizeMe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40f12f3e",
   "metadata": {
    "id": "3Ay5_5Y0ThrI"
   },
   "outputs": [],
   "source": [
    "dpm = DontPatronizeMe('.', '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9146307a",
   "metadata": {},
   "source": [
    "## Dataset required (run the cell below first)\n",
    "\n",
    "The notebook only fetches the **Python loader** (`dont_patronize_me.py`). The **actual data files** are not in the public repo:\n",
    "\n",
    "- **`dontpatronizeme_pcl.tsv`** – Task 1 (binary PCL labels)\n",
    "- **`dontpatronizeme_categories.tsv`** – Task 2 (category labels)\n",
    "\n",
    "**How to get them:**  \n",
    "1. **Course:** If this is for a module, the data may be on the course VLE or shared drive – use that first.  \n",
    "2. **Otherwise:** Request access from the task organisers: https://forms.gle/VN8hwbdGYkf5KHiKA  \n",
    "\n",
    "Place both TSV files in the **same folder as this notebook** (e.g. `BestModel/`).  \n",
    "\n",
    "The cell below downloads the **practice split** CSVs (train/dev paragraph IDs) from the repo and checks that the TSV files are present before you run `dpm.load_task1()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50f37f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already have train_semeval_parids-labels.csv\n",
      "Already have dev_semeval_parids-labels.csv\n",
      "Missing dataset files: dontpatronizeme_pcl.tsv and/or dontpatronizeme_categories.tsv\n",
      "Get them from your course materials or request at: https://forms.gle/VN8hwbdGYkf5KHiKA\n",
      "Place both TSV files in this notebook's folder (e.g. BestModel/).\n"
     ]
    }
   ],
   "source": [
    "# Download practice split CSVs (train/dev paragraph IDs) if missing; check for required TSV data files\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "base_url = \"https://raw.githubusercontent.com/Perez-AlmendrosC/dontpatronizeme/master/semeval-2022/practice%20splits\"\n",
    "for name in [\"train_semeval_parids-labels.csv\", \"dev_semeval_parids-labels.csv\"]:\n",
    "    if not os.path.isfile(name):\n",
    "        urlretrieve(f\"{base_url}/{name}\", name)\n",
    "        print(f\"Downloaded {name}\")\n",
    "    else:\n",
    "        print(f\"Already have {name}\")\n",
    "# Check for required dataset TSV files (not in the public repo)\n",
    "pcl_tsv = \"dontpatronizeme_pcl.tsv\"\n",
    "cat_tsv = \"dontpatronizeme_categories.tsv\"\n",
    "if os.path.isfile(pcl_tsv) and os.path.isfile(cat_tsv):\n",
    "    print(\"Dataset TSV files found. You can run dpm.load_task1() and load_task2() next.\")\n",
    "else:\n",
    "    print(\"Missing dataset files:\", pcl_tsv, \"and/or\", cat_tsv)\n",
    "    print(\"Get them from your course materials or request at: https://forms.gle/VN8hwbdGYkf5KHiKA\")\n",
    "    print(\"Place both TSV files in this notebook's folder (e.g. BestModel/).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afb45a26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2r3USK4eThrJ",
    "outputId": "b6388371-0bb4-4e9f-c6a2-04524710e421"
   },
   "outputs": [],
   "source": [
    "dpm.load_task1()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6d2976",
   "metadata": {
    "id": "P0YcdU80IbiS"
   },
   "source": [
    "# Load paragraph IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84f614fb",
   "metadata": {
    "id": "8AReWYHYOUqx"
   },
   "outputs": [],
   "source": [
    "trids = pd.read_csv('train_semeval_parids-labels.csv')\n",
    "teids = pd.read_csv('dev_semeval_parids-labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2ed06b8",
   "metadata": {
    "id": "7IfCZjwQ16MS"
   },
   "outputs": [],
   "source": [
    "trids.par_id = trids.par_id.astype(str)\n",
    "teids.par_id = teids.par_id.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9c00692",
   "metadata": {
    "id": "nFnGtWdHJldw"
   },
   "outputs": [],
   "source": [
    "data=dpm.train_task1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f269b63c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "rmUBJhljbnpN",
    "outputId": "31cd4b87-61fe-4a57-87f4-77f5edc9a680"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>art_id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>country</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>orig_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@@24942188</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>ph</td>\n",
       "      <td>We 're living in times of absolute insanity , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@@21968160</td>\n",
       "      <td>migrant</td>\n",
       "      <td>gh</td>\n",
       "      <td>In Libya today , there are countless number of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@@16584954</td>\n",
       "      <td>immigrant</td>\n",
       "      <td>ie</td>\n",
       "      <td>\"White House press secretary Sean Spicer said ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@@7811231</td>\n",
       "      <td>disabled</td>\n",
       "      <td>nz</td>\n",
       "      <td>Council customers only signs would be displaye...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@@1494111</td>\n",
       "      <td>refugee</td>\n",
       "      <td>ca</td>\n",
       "      <td>\"\"\" Just like we received migrants fleeing El ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10464</th>\n",
       "      <td>10465</td>\n",
       "      <td>@@14297363</td>\n",
       "      <td>women</td>\n",
       "      <td>lk</td>\n",
       "      <td>\"Sri Lankan norms and culture inhibit women fr...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10465</th>\n",
       "      <td>10466</td>\n",
       "      <td>@@70091353</td>\n",
       "      <td>vulnerable</td>\n",
       "      <td>ph</td>\n",
       "      <td>He added that the AFP will continue to bank on...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10466</th>\n",
       "      <td>10467</td>\n",
       "      <td>@@20282330</td>\n",
       "      <td>in-need</td>\n",
       "      <td>ng</td>\n",
       "      <td>\"\"\" She has one huge platform , and informatio...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10467</th>\n",
       "      <td>10468</td>\n",
       "      <td>@@16753236</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>in</td>\n",
       "      <td>\"\"\" Anja Ringgren Loven I ca n't find a word t...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10468</th>\n",
       "      <td>10469</td>\n",
       "      <td>@@16779383</td>\n",
       "      <td>homeless</td>\n",
       "      <td>ie</td>\n",
       "      <td>\"\"\" Guinness World Record of 540lbs of 7-layer...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10469 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      par_id      art_id     keyword country  \\\n",
       "0          1  @@24942188    hopeless      ph   \n",
       "1          2  @@21968160     migrant      gh   \n",
       "2          3  @@16584954   immigrant      ie   \n",
       "3          4   @@7811231    disabled      nz   \n",
       "4          5   @@1494111     refugee      ca   \n",
       "...      ...         ...         ...     ...   \n",
       "10464  10465  @@14297363       women      lk   \n",
       "10465  10466  @@70091353  vulnerable      ph   \n",
       "10466  10467  @@20282330     in-need      ng   \n",
       "10467  10468  @@16753236    hopeless      in   \n",
       "10468  10469  @@16779383    homeless      ie   \n",
       "\n",
       "                                                    text  label orig_label  \n",
       "0      We 're living in times of absolute insanity , ...      0          0  \n",
       "1      In Libya today , there are countless number of...      0          0  \n",
       "2      \"White House press secretary Sean Spicer said ...      0          0  \n",
       "3      Council customers only signs would be displaye...      0          0  \n",
       "4      \"\"\" Just like we received migrants fleeing El ...      0          0  \n",
       "...                                                  ...    ...        ...  \n",
       "10464  \"Sri Lankan norms and culture inhibit women fr...      0          1  \n",
       "10465  He added that the AFP will continue to bank on...      0          0  \n",
       "10466  \"\"\" She has one huge platform , and informatio...      1          3  \n",
       "10467  \"\"\" Anja Ringgren Loven I ca n't find a word t...      1          4  \n",
       "10468  \"\"\" Guinness World Record of 540lbs of 7-layer...      1          3  \n",
       "\n",
       "[10469 rows x 7 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5da9b5",
   "metadata": {
    "id": "8lXrNj_Ww_FC"
   },
   "source": [
    "\n",
    "\n",
    "# Rebuild training set (Task 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18980040",
   "metadata": {
    "id": "BOxDR1H2g_3p"
   },
   "outputs": [],
   "source": [
    "rows = [] # will contain par_id, label and text\n",
    "for idx in range(len(trids)):\n",
    "  parid = trids.par_id[idx]\n",
    "  #print(parid)\n",
    "  # select row from original dataset to retrieve `text` and binary label\n",
    "  keyword = data.loc[data.par_id == parid].keyword.values[0]\n",
    "  text = data.loc[data.par_id == parid].text.values[0]\n",
    "  label = data.loc[data.par_id == parid].label.values[0]\n",
    "  rows.append({\n",
    "      'par_id':parid,\n",
    "      'community':keyword,\n",
    "      'text':text,\n",
    "      'label':label\n",
    "  })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42bb6211",
   "metadata": {
    "id": "N7UDCLIgcrCl"
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a524edd",
   "metadata": {
    "id": "8e3E08Yown5p"
   },
   "outputs": [],
   "source": [
    "trdf1 = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cad54f3c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "pgxtVuhr9ZFG",
    "outputId": "578fccba-d2a7-4045-d0fc-5cc594b0c426"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>community</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4341</td>\n",
       "      <td>poor-families</td>\n",
       "      <td>The scheme saw an estimated 150,000 children f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4136</td>\n",
       "      <td>homeless</td>\n",
       "      <td>Durban 's homeless communities reconciliation ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10352</td>\n",
       "      <td>poor-families</td>\n",
       "      <td>The next immediate problem that cropped up was...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8279</td>\n",
       "      <td>vulnerable</td>\n",
       "      <td>Far more important than the implications for t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1164</td>\n",
       "      <td>poor-families</td>\n",
       "      <td>To strengthen child-sensitive social protectio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8370</th>\n",
       "      <td>8380</td>\n",
       "      <td>refugee</td>\n",
       "      <td>Rescue teams search for survivors on the rubbl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8371</th>\n",
       "      <td>8381</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>The launch of ' Happy Birthday ' took place la...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8372</th>\n",
       "      <td>8382</td>\n",
       "      <td>homeless</td>\n",
       "      <td>The unrest has left at least 20,000 people dea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8373</th>\n",
       "      <td>8383</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>You have to see it from my perspective . I may...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>8384</td>\n",
       "      <td>disabled</td>\n",
       "      <td>Yet there was one occasion when we went to the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8375 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     par_id      community                                               text  \\\n",
       "0      4341  poor-families  The scheme saw an estimated 150,000 children f...   \n",
       "1      4136       homeless  Durban 's homeless communities reconciliation ...   \n",
       "2     10352  poor-families  The next immediate problem that cropped up was...   \n",
       "3      8279     vulnerable  Far more important than the implications for t...   \n",
       "4      1164  poor-families  To strengthen child-sensitive social protectio...   \n",
       "...     ...            ...                                                ...   \n",
       "8370   8380        refugee  Rescue teams search for survivors on the rubbl...   \n",
       "8371   8381       hopeless  The launch of ' Happy Birthday ' took place la...   \n",
       "8372   8382       homeless  The unrest has left at least 20,000 people dea...   \n",
       "8373   8383       hopeless  You have to see it from my perspective . I may...   \n",
       "8374   8384       disabled  Yet there was one occasion when we went to the...   \n",
       "\n",
       "      label  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "...     ...  \n",
       "8370      0  \n",
       "8371      0  \n",
       "8372      0  \n",
       "8373      0  \n",
       "8374      0  \n",
       "\n",
       "[8375 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trdf1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2425615",
   "metadata": {
    "id": "O1KGYmpnxDjt"
   },
   "source": [
    "# Rebuild test set (Task 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acffc33a",
   "metadata": {
    "id": "T6FLgB6KxGI2"
   },
   "outputs": [],
   "source": [
    "rows = [] # will contain par_id, label and text\n",
    "for idx in range(len(teids)):\n",
    "  parid = teids.par_id[idx]\n",
    "  #print(parid)\n",
    "  # select row from original dataset\n",
    "  keyword = data.loc[data.par_id == parid].keyword.values[0]\n",
    "  text = data.loc[data.par_id == parid].text.values[0]\n",
    "  label = data.loc[data.par_id == parid].label.values[0]\n",
    "  rows.append({\n",
    "      'par_id':parid,\n",
    "      'community':keyword,\n",
    "      'text':text,\n",
    "      'label':label\n",
    "  })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21898a77",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YbB9GdzJxRAH",
    "outputId": "c78e311e-9502-4644-b6f7-0c64f64aa66f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2094"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "549a1b46",
   "metadata": {
    "id": "vhBhTRIyxSaQ"
   },
   "outputs": [],
   "source": [
    "tedf1 = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb8b6d1d",
   "metadata": {
    "id": "CuaH7i69aud6"
   },
   "outputs": [],
   "source": [
    "# Shuffle rows (random.shuffle() is for lists; use .sample() for DataFrames)\n",
    "tedf1 = tedf1.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d07643",
   "metadata": {
    "id": "xK6FY70KZ6TY"
   },
   "source": [
    "# RoBERTa Baseline for Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a35eb9f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-pvjbu_8h1n",
    "outputId": "0a9da7ae-181c-40a5-a438-220f5ab960b5"
   },
   "outputs": [],
   "source": [
    "# downsample negative instances\n",
    "pcldf = trdf1[trdf1.label==1]\n",
    "npos = len(pcldf)\n",
    "\n",
    "training_set1 = pd.concat([pcldf,trdf1[trdf1.label==0][:npos*2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5f1819f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "mpSqMp3d8iYu",
    "outputId": "037d4f45-eab5-4f04-e9a5-1aa64c46323d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>community</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4341</td>\n",
       "      <td>poor-families</td>\n",
       "      <td>The scheme saw an estimated 150,000 children f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4136</td>\n",
       "      <td>homeless</td>\n",
       "      <td>Durban 's homeless communities reconciliation ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10352</td>\n",
       "      <td>poor-families</td>\n",
       "      <td>The next immediate problem that cropped up was...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8279</td>\n",
       "      <td>vulnerable</td>\n",
       "      <td>Far more important than the implications for t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1164</td>\n",
       "      <td>poor-families</td>\n",
       "      <td>To strengthen child-sensitive social protectio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>1775</td>\n",
       "      <td>refugee</td>\n",
       "      <td>Last but not the least element of culpability ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>1776</td>\n",
       "      <td>refugee</td>\n",
       "      <td>Then , taking the art of counter-intuitive non...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>1777</td>\n",
       "      <td>refugee</td>\n",
       "      <td>Kagunga village was reported to lack necessary...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>1778</td>\n",
       "      <td>vulnerable</td>\n",
       "      <td>\"After her parents high-profile divorce after ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>1779</td>\n",
       "      <td>in-need</td>\n",
       "      <td>\"Last night One News reported on leaked Minist...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2382 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     par_id      community                                               text  \\\n",
       "0      4341  poor-families  The scheme saw an estimated 150,000 children f...   \n",
       "1      4136       homeless  Durban 's homeless communities reconciliation ...   \n",
       "2     10352  poor-families  The next immediate problem that cropped up was...   \n",
       "3      8279     vulnerable  Far more important than the implications for t...   \n",
       "4      1164  poor-families  To strengthen child-sensitive social protectio...   \n",
       "...     ...            ...                                                ...   \n",
       "2377   1775        refugee  Last but not the least element of culpability ...   \n",
       "2378   1776        refugee  Then , taking the art of counter-intuitive non...   \n",
       "2379   1777        refugee  Kagunga village was reported to lack necessary...   \n",
       "2380   1778     vulnerable  \"After her parents high-profile divorce after ...   \n",
       "2381   1779        in-need  \"Last night One News reported on leaked Minist...   \n",
       "\n",
       "      label  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "...     ...  \n",
       "2377      0  \n",
       "2378      0  \n",
       "2379      0  \n",
       "2380      0  \n",
       "2381      0  \n",
       "\n",
       "[2382 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfab4e98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538,
     "referenced_widgets": [
      "de026e2d1ec848fbb35faf1746e7579d",
      "7a0d26d292e54498a15bc2e54e6c3aee",
      "13bc966911b1433ab6f8245f88b86e2d",
      "ec69c0f693b74ac8b737816b1efaa8bf",
      "cf4fb870564043cfbc171ae05143ec5f",
      "abc4d60485bf40d7abf3cbcf212e39a2",
      "85ea942b0e194d2a9160f82494fff8e0",
      "6b2a3cde2cdb4bc6a9d0623363c66266",
      "a287d92682d644daa34030f58227540f",
      "2eea385dfcf745e6b92c37eb6cd901f4",
      "59c41a4934cf4ef2b467ae5d97b615f0",
      "a90282c995cc4c6db59eaa51e3414ad1",
      "d76e461fca524e04810c38b44ad51185",
      "b4d34c0c2e364f88b70036cbff6f780a",
      "4d22ac94c09d4802b4664e456278308a",
      "594d094f060e4481977901e11c2ddaf2",
      "b276fc7fd7954ec09fabbcad64b93508",
      "29ad13a85dc44e4e919bed1daddf0935",
      "c0b81615b8fc4b8d8a48232d029e717d",
      "c1dc117db5c444bd918b9ab70b587f48",
      "fc14f76deb2549b3a5c6bce9ea3dd7e3",
      "a8757d3393f04a55a5bea7f923944281",
      "df46941823a540f787e2e9dad52243d3",
      "904714fa04be424da224c801f06d52f6",
      "790e423a21b840978da497d9d35634a6",
      "6cc05e8394ac491999930b9493be855e",
      "8cefe2ef3c984e3a8ad1bb8ecb7f0dbb",
      "4ec670884e2247ec872defaa5bf7dcc5",
      "3d7e4c3c0af84bc4940d2e25ad8a5162",
      "4f8aa1c4c8914693a24523c1064ecf97",
      "ab2d97c595ff4e55969bc2f1415f747d",
      "60b8f43949894143a83263e96d0ac3fa",
      "703f69d98e9947f3aeaba07b51d64f3c",
      "59458022ec4547beba130ce755946427",
      "26178b1ed5164ca7bcea84b65fc95522",
      "ac45cf1a895f4ba39c5be0ad136c4591",
      "117489e4902040ae97cb222f8c4dda12",
      "ba09b68a05644dd1b7d12a19396fb3b8",
      "37531d1ef87f45c99df60fb6a8a66d78",
      "1c61f90f85a54cbb9d2ccdbf614eb8d5",
      "c11ef82d87114a59868d9d7810b936db",
      "a8de20f8116142f6bf25aef25f37ad85",
      "32fe020b5dc54143af2830ec578eecdf",
      "2fcffe85dbcc4c91b840c61799b82772",
      "2c3f59321aac4ea78e4c70618f907e08",
      "ff3206118d3043b3a9b757ec3ca01d9f",
      "d1343667008643c8a893bfae962503c1",
      "384f2a4804ed458498b35f04d32e41b5",
      "f7e1e00cad5449dfb55c6a920a292540",
      "ec68ce238bb04063a74afd67a4f1e877",
      "05e6b65f527c48e5ab8aaa8a220287c0",
      "ee3cdac0740d43188518e097ae5863a5",
      "6f8e6355fcb74fc98cc641bc36bd1707",
      "19628b1c68004e9a98ecb5a934d57d2d",
      "cafdb944408b42eaacec5b2e8566962b",
      "b8654137c93f4a70b0fb8f7e692f7673",
      "b088cb07387d4a46b3c7d4d7cc9a5aba",
      "e567e754183b42d69d3d200a4517b132",
      "e4c905c262994b7d9197f77b2da2c178",
      "f0b59d4d691c44a4a7dbb40991518d36",
      "fe372945c13845e5bd01ca4e153ed61c",
      "c3a17fa9e8da4d9fb571e307f75ac144",
      "23ee94259c41435ea19264f4a2937585",
      "c3cafc815e4444a8998e608cd9c9300d",
      "49fd3eaa74fa493fbe7324607888c542",
      "6870cb8717ba407c81d0b7c79ad27d26",
      "d32db030dff24fe3bd1983a44c703311",
      "ee1cc81a307a4ea6ac00b65a4d314877",
      "d16d01773a334ccb8a9231d3cae6e0f4",
      "c43f7ff02eb74e0d900029f97652a973",
      "d6a37bb80db94947810fa1d69b8b416b",
      "4f8b629635194d759b9c91f37a445632",
      "d48d137548464c3387dd51494cb969bf",
      "89f9d8cab0c44b58afee34914198a9e6",
      "3119accf975446eda52b0125571322a4",
      "bac5decd48b74036a270f70a05c3f80e",
      "2c646f33655d4646b70afef87232d5a1",
      "82f733de38ef4c5f8734cbdf47ec1a01",
      "818e5dbea2094a97a18974aebe4ddb86",
      "c2dae6a605f842d3aaad1f86b2e332b6",
      "197dca1cad8b425bb4622c9d5da461dc",
      "1cf670526680446db48fbf64b1cae0a6",
      "ece446ccb0d3496a81dc0250fff9039d",
      "d7d3e0bd4a9c43dd9946a8a63b12d1d7",
      "f879197b8c2443278e280f82f20cc609",
      "c983b2e75ec44867a14f6d3abdfff2ec",
      "d1df90f8eead4f5e8718fd42ec0d5e40",
      "b3f807cfae5a44fcbf1069817e6fb79d",
      "a308011d2efd403fb6b8d250d8f98fa9",
      "770ad4abfc4f4eeebefade5afcad22a3",
      "226d2e2955444f9ead05b5991d7939e5",
      "9f03facdd7704ab9be2bd65f1060f215",
      "fc122d487cbd4ab69e78f1b9425774ba",
      "21c2295bc2a54d979f2a5404f6a7ecb1",
      "b4bcc997cfa4444287370bbb4819cb43",
      "4fbbc5b908c14198b8c86ca2208bd890",
      "5bc982f17aec46b3b7f8308f567f6296",
      "f1fe964e4d2b4ebb8f76b3d8debdaab6",
      "7e3df3b58c7e4117b0a8b8fc45dffa01",
      "6851a6f291a04bd59da6cf04d6f762aa",
      "3cd79b7a96784504a28dce435f9de5b5",
      "d79bd01e1fe44c12ac530376324d9e0e",
      "4a03ac52afa84bfd82ced188892b1958",
      "8351a84b9c914d80a54ac57a2fb18304",
      "419ce58d2ed14589a3d2e1cd7b477e0f",
      "568d424c94094d669282ed72b4cf0be4",
      "7fe11f4ffd3747079b8de4453b29dbac",
      "22a8be9fae3245cca79dc7904ed4f49d",
      "ed1ad3ad89334675babf56f9737a17fb",
      "dba102bf2b3249c8907d4fe1d5cf0e82"
     ]
    },
    "id": "PoW_s23AZ_DG",
    "outputId": "cae26801-a680-4d5b-9d76-d56872b5e611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying config: {'num_train_epochs': 8, 'learning_rate': 2e-05, 'weight': [1.0, 2.0]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:484: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:637: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "5it [00:15,  3.06s/it]                       \n",
      "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:924: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Epoch 1 of 8:   0%|          | 0/8 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:950: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "Epochs 1/8. Running Loss:    0.7021: 100%|██████████| 298/298 [00:43<00:00,  6.79it/s]\n",
      "Epochs 2/8. Running Loss:    0.2742: 100%|██████████| 298/298 [00:43<00:00,  6.81it/s]\n",
      "Epochs 3/8. Running Loss:    0.1434: 100%|██████████| 298/298 [00:43<00:00,  6.79it/s]\n",
      "Epochs 4/8. Running Loss:    0.9526: 100%|██████████| 298/298 [00:44<00:00,  6.74it/s]\n",
      "Epochs 5/8. Running Loss:    0.0026: 100%|██████████| 298/298 [00:44<00:00,  6.63it/s]\n",
      "Epochs 6/8. Running Loss:    0.0005: 100%|██████████| 298/298 [00:44<00:00,  6.75it/s]\n",
      "Epochs 7/8. Running Loss:    0.0004: 100%|██████████| 298/298 [00:44<00:00,  6.74it/s]\n",
      "Epochs 8/8. Running Loss:    0.0003: 100%|██████████| 298/298 [00:44<00:00,  6.74it/s]\n",
      "Epoch 8 of 8: 100%|██████████| 8/8 [05:53<00:00, 44.16s/it]\n",
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "5it [00:13,  2.62s/it]                       \n",
      "Predicting:   0%|          | 0/21 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:2260: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Predicting: 100%|██████████| 21/21 [00:08<00:00,  2.60it/s]\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.5468\n",
      "\n",
      "Trying config: {'num_train_epochs': 10, 'learning_rate': 2e-05, 'weight': [1.0, 2.0]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:484: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:637: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "5it [00:12,  2.54s/it]                       \n",
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:924: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Epoch 1 of 10:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:950: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Epochs 1/10. Running Loss:    0.3941: 100%|██████████| 298/298 [00:43<00:00,  6.79it/s]\n",
      "Epochs 2/10. Running Loss:    0.0895: 100%|██████████| 298/298 [00:43<00:00,  6.83it/s]\n",
      "Epochs 3/10. Running Loss:    0.1243: 100%|██████████| 298/298 [00:43<00:00,  6.84it/s]\n",
      "Epochs 4/10. Running Loss:    0.0005: 100%|██████████| 298/298 [00:43<00:00,  6.83it/s]\n",
      "Epochs 5/10. Running Loss:    0.0005: 100%|██████████| 298/298 [00:44<00:00,  6.76it/s]\n",
      "Epochs 6/10. Running Loss:    0.0003: 100%|██████████| 298/298 [00:43<00:00,  6.82it/s]\n",
      "Epochs 7/10. Running Loss:    0.0010: 100%|██████████| 298/298 [00:43<00:00,  6.82it/s]\n",
      "Epochs 8/10. Running Loss:    0.0001: 100%|██████████| 298/298 [00:43<00:00,  6.82it/s]\n",
      "Epochs 9/10. Running Loss:    0.0001: 100%|██████████| 298/298 [00:44<00:00,  6.76it/s]\n",
      "Epochs 10/10. Running Loss:    0.0002: 100%|██████████| 298/298 [00:44<00:00,  6.67it/s]\n",
      "Epoch 10 of 10: 100%|██████████| 10/10 [07:18<00:00, 43.87s/it]\n",
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "5it [00:12,  2.47s/it]                       \n",
      "Predicting:   0%|          | 0/21 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:2260: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Predicting: 100%|██████████| 21/21 [00:07<00:00,  2.72it/s]\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.5284\n",
      "\n",
      "Trying config: {'num_train_epochs': 12, 'learning_rate': 2e-05, 'weight': [1.0, 2.0]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:484: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:637: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "5it [00:12,  2.48s/it]                       \n",
      "Epoch:   0%|          | 0/12 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:924: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Epoch 1 of 12:   0%|          | 0/12 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:950: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "Epochs 1/12. Running Loss:    1.2566: 100%|██████████| 298/298 [00:43<00:00,  6.87it/s]\n",
      "Epochs 2/12. Running Loss:    0.1746: 100%|██████████| 298/298 [00:43<00:00,  6.87it/s]\n",
      "Epochs 3/12. Running Loss:    0.8479: 100%|██████████| 298/298 [00:43<00:00,  6.86it/s]\n",
      "Epochs 4/12. Running Loss:    0.0035: 100%|██████████| 298/298 [00:43<00:00,  6.87it/s]\n",
      "Epochs 5/12. Running Loss:    0.4214: 100%|██████████| 298/298 [00:43<00:00,  6.85it/s]\n",
      "Epochs 6/12. Running Loss:    0.0005: 100%|██████████| 298/298 [00:43<00:00,  6.87it/s]\n",
      "Epochs 7/12. Running Loss:    0.0001: 100%|██████████| 298/298 [00:43<00:00,  6.86it/s]\n",
      "Epochs 8/12. Running Loss:    0.0001: 100%|██████████| 298/298 [00:43<00:00,  6.86it/s]\n",
      "Epochs 9/12. Running Loss:    0.0001: 100%|██████████| 298/298 [00:43<00:00,  6.86it/s]\n",
      "Epochs 10/12. Running Loss:    0.0000: 100%|██████████| 298/298 [00:43<00:00,  6.86it/s]\n",
      "Epochs 11/12. Running Loss:    0.0001: 100%|██████████| 298/298 [00:44<00:00,  6.75it/s]\n",
      "Epochs 12/12. Running Loss:    0.0000: 100%|██████████| 298/298 [00:43<00:00,  6.85it/s]\n",
      "Epoch 12 of 12: 100%|██████████| 12/12 [08:41<00:00, 43.49s/it]\n",
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "5it [00:12,  2.44s/it]                       \n",
      "Predicting:   0%|          | 0/21 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:2260: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Predicting: 100%|██████████| 21/21 [00:07<00:00,  2.71it/s]\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.5299\n",
      "\n",
      "Trying config: {'num_train_epochs': 10, 'learning_rate': 1e-05, 'weight': [1.0, 2.0]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:484: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:637: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "5it [00:12,  2.43s/it]                       \n",
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:924: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Epoch 1 of 10:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:950: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "Epochs 1/10. Running Loss:    0.5549: 100%|██████████| 298/298 [00:43<00:00,  6.85it/s]\n",
      "Epochs 2/10. Running Loss:    0.1390: 100%|██████████| 298/298 [00:43<00:00,  6.85it/s]\n",
      "Epochs 3/10. Running Loss:    0.1488: 100%|██████████| 298/298 [00:43<00:00,  6.85it/s]\n",
      "Epochs 4/10. Running Loss:    0.0023: 100%|██████████| 298/298 [00:43<00:00,  6.84it/s]\n",
      "Epochs 5/10. Running Loss:    0.0018: 100%|██████████| 298/298 [00:43<00:00,  6.85it/s]\n",
      "Epochs 6/10. Running Loss:    0.0009: 100%|██████████| 298/298 [00:43<00:00,  6.84it/s]\n",
      "Epochs 7/10. Running Loss:    0.0008: 100%|██████████| 298/298 [00:43<00:00,  6.84it/s]\n",
      "Epochs 8/10. Running Loss:    0.0004: 100%|██████████| 298/298 [00:43<00:00,  6.84it/s]\n",
      "Epochs 9/10. Running Loss:    0.0003: 100%|██████████| 298/298 [00:43<00:00,  6.84it/s]\n",
      "Epochs 10/10. Running Loss:    0.2876: 100%|██████████| 298/298 [00:43<00:00,  6.84it/s]\n",
      "Epoch 10 of 10: 100%|██████████| 10/10 [07:15<00:00, 43.53s/it]\n",
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "5it [00:12,  2.42s/it]                       \n",
      "Predicting:   0%|          | 0/21 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:2260: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Predicting: 100%|██████████| 21/21 [00:07<00:00,  2.70it/s]\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.5468\n",
      "\n",
      "Trying config: {'num_train_epochs': 10, 'learning_rate': 3e-05, 'weight': [1.0, 2.0]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:484: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:637: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "5it [00:12,  2.42s/it]                       \n",
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:924: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Epoch 1 of 10:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:950: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "Epochs 1/10. Running Loss:    0.7384: 100%|██████████| 298/298 [00:44<00:00,  6.72it/s]\n",
      "Epochs 2/10. Running Loss:    0.5465: 100%|██████████| 298/298 [00:43<00:00,  6.87it/s]\n",
      "Epochs 3/10. Running Loss:    0.7121: 100%|██████████| 298/298 [00:43<00:00,  6.86it/s]\n",
      "Epochs 4/10. Running Loss:    0.0027: 100%|██████████| 298/298 [00:43<00:00,  6.85it/s]\n",
      "Epochs 5/10. Running Loss:    0.0012: 100%|██████████| 298/298 [00:43<00:00,  6.85it/s]\n",
      "Epochs 6/10. Running Loss:    0.0011: 100%|██████████| 298/298 [00:43<00:00,  6.86it/s]\n",
      "Epochs 7/10. Running Loss:    0.0002: 100%|██████████| 298/298 [00:43<00:00,  6.85it/s]\n",
      "Epochs 8/10. Running Loss:    0.0003: 100%|██████████| 298/298 [00:43<00:00,  6.85it/s]\n",
      "Epochs 9/10. Running Loss:    0.0000: 100%|██████████| 298/298 [00:43<00:00,  6.85it/s]\n",
      "Epochs 10/10. Running Loss:    0.0002: 100%|██████████| 298/298 [00:43<00:00,  6.85it/s]\n",
      "Epoch 10 of 10: 100%|██████████| 10/10 [07:15<00:00, 43.56s/it]\n",
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "5it [00:12,  2.45s/it]                       \n",
      "Predicting:   0%|          | 0/21 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:2260: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Predicting: 100%|██████████| 21/21 [00:07<00:00,  2.69it/s]\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.5393\n",
      "\n",
      "Trying config: {'num_train_epochs': 10, 'learning_rate': 2e-05, 'weight': [1.0, 3.0]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:484: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:637: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "5it [00:12,  2.46s/it]                       \n",
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:924: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Epoch 1 of 10:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:950: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "Epochs 1/10. Running Loss:    0.8848: 100%|██████████| 298/298 [00:43<00:00,  6.87it/s]\n",
      "Epochs 2/10. Running Loss:    0.4961: 100%|██████████| 298/298 [00:43<00:00,  6.89it/s]\n",
      "Epochs 3/10. Running Loss:    0.3554: 100%|██████████| 298/298 [00:43<00:00,  6.87it/s]\n",
      "Epochs 4/10. Running Loss:    0.3207: 100%|██████████| 298/298 [00:43<00:00,  6.87it/s]\n",
      "Epochs 5/10. Running Loss:    0.0830: 100%|██████████| 298/298 [00:43<00:00,  6.87it/s]\n",
      "Epochs 6/10. Running Loss:    0.0005: 100%|██████████| 298/298 [00:43<00:00,  6.87it/s]\n",
      "Epochs 7/10. Running Loss:    0.0015: 100%|██████████| 298/298 [00:44<00:00,  6.74it/s]\n",
      "Epochs 8/10. Running Loss:    0.0005: 100%|██████████| 298/298 [00:43<00:00,  6.89it/s]\n",
      "Epochs 9/10. Running Loss:    0.0002: 100%|██████████| 298/298 [00:43<00:00,  6.89it/s]\n",
      "Epochs 10/10. Running Loss:    0.0003: 100%|██████████| 298/298 [00:43<00:00,  6.89it/s]\n",
      "Epoch 10 of 10: 100%|██████████| 10/10 [07:14<00:00, 43.43s/it]\n",
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "5it [00:11,  2.38s/it]                       \n",
      "Predicting:   0%|          | 0/21 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:2260: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Predicting: 100%|██████████| 21/21 [00:07<00:00,  2.69it/s]\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.5523\n",
      "\n",
      "Trying config: {'num_train_epochs': 10, 'learning_rate': 2e-05, 'weight': [1.0, 1.5]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:484: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:637: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "5it [00:11,  2.39s/it]                       \n",
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:924: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Epoch 1 of 10:   0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:950: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "Epochs 1/10. Running Loss:    0.0886: 100%|██████████| 298/298 [00:43<00:00,  6.90it/s]\n",
      "Epochs 2/10. Running Loss:    0.0620: 100%|██████████| 298/298 [00:43<00:00,  6.91it/s]\n",
      "Epochs 3/10. Running Loss:    0.2307: 100%|██████████| 298/298 [00:43<00:00,  6.91it/s]\n",
      "Epochs 4/10. Running Loss:    0.0054: 100%|██████████| 298/298 [00:43<00:00,  6.91it/s]\n",
      "Epochs 5/10. Running Loss:    0.0007: 100%|██████████| 298/298 [00:43<00:00,  6.91it/s]\n",
      "Epochs 6/10. Running Loss:    0.5366: 100%|██████████| 298/298 [00:43<00:00,  6.90it/s]\n",
      "Epochs 7/10. Running Loss:    0.0002: 100%|██████████| 298/298 [00:43<00:00,  6.91it/s]\n",
      "Epochs 8/10. Running Loss:    0.0001: 100%|██████████| 298/298 [00:43<00:00,  6.91it/s]\n",
      "Epochs 9/10. Running Loss:    0.0000: 100%|██████████| 298/298 [00:43<00:00,  6.91it/s]\n",
      "Epochs 10/10. Running Loss:    0.0001: 100%|██████████| 298/298 [00:43<00:00,  6.91it/s]\n",
      "Epoch 10 of 10: 100%|██████████| 10/10 [07:11<00:00, 43.15s/it]\n",
      "INFO:simpletransformers.classification.classification_model: Training of roberta model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "5it [00:11,  2.39s/it]                       \n",
      "Predicting:   0%|          | 0/21 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:2260: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Predicting: 100%|██████████| 21/21 [00:07<00:00,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.5078\n",
      "\n",
      "Best config: {'num_train_epochs': 10, 'learning_rate': 2e-05, 'weight': [1.0, 3.0]}\n",
      "Best F1: 0.5523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# Epoch search centred at 10 (Pérez-Almendros et al., 2020); also tune lr and class weight.\n",
    "configs = [\n",
    "    {\"num_train_epochs\": 8,  \"learning_rate\": 2e-5, \"weight\": [1.0, 2.0]},\n",
    "    {\"num_train_epochs\": 10, \"learning_rate\": 2e-5, \"weight\": [1.0, 2.0]},\n",
    "    {\"num_train_epochs\": 12, \"learning_rate\": 2e-5, \"weight\": [1.0, 2.0]},\n",
    "    {\"num_train_epochs\": 10, \"learning_rate\": 1e-5, \"weight\": [1.0, 2.0]},\n",
    "    {\"num_train_epochs\": 10, \"learning_rate\": 3e-5, \"weight\": [1.0, 2.0]},\n",
    "    {\"num_train_epochs\": 10, \"learning_rate\": 2e-5, \"weight\": [1.0, 3.0]},\n",
    "    {\"num_train_epochs\": 10, \"learning_rate\": 2e-5, \"weight\": [1.0, 1.5]},\n",
    "]\n",
    "\n",
    "best_f1 = 0\n",
    "best_config = None\n",
    "best_preds = None\n",
    "\n",
    "for config in configs:\n",
    "    print(f\"\\nTrying config: {config}\")\n",
    "    \n",
    "    model_args = ClassificationArgs(\n",
    "        num_train_epochs=config[\"num_train_epochs\"],\n",
    "        learning_rate=config[\"learning_rate\"],\n",
    "        no_save=True,\n",
    "        no_cache=True,\n",
    "        overwrite_output_dir=True,\n",
    "        max_seq_length=256,\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,\n",
    "        silent=False\n",
    "    )\n",
    "    \n",
    "    model = ClassificationModel(\n",
    "        \"roberta\",\n",
    "        \"cardiffnlp/twitter-roberta-base-hate\",\n",
    "        args=model_args,\n",
    "        num_labels=2,\n",
    "        weight=config[\"weight\"],\n",
    "        use_cuda=cuda_available\n",
    "    )\n",
    "    \n",
    "    model.train_model(training_set1[['text', 'label']])\n",
    "    preds, _ = model.predict(tedf1.text.tolist())\n",
    "    \n",
    "    f1 = f1_score(tedf1.label.tolist(), preds)\n",
    "    print(f\"F1: {f1:.4f}\")\n",
    "    \n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_config = config\n",
    "        best_preds = preds\n",
    "        best_model = model\n",
    "\n",
    "print(f\"\\nBest config: {best_config}\")\n",
    "print(f\"Best F1: {best_f1:.4f}\")\n",
    "\n",
    "# Save dev predictions to submission/\n",
    "import os\n",
    "os.makedirs('submission', exist_ok=True)\n",
    "labels2file([[k] for k in best_preds], 'submission/dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da63aaac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h5oxHt2R6t2I",
    "outputId": "27505e5d-896b-4d63-dc53-905cc34d7fd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({np.int64(0): 1786, np.int64(1): 308})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(best_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c9583c8",
   "metadata": {
    "id": "kzupJuwTafKa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8it [00:15,  1.95s/it]                       \n",
      "Predicting:   0%|          | 0/39 [00:00<?, ?it/s]c:\\Users\\Serene\\Documents\\nlp-pcl-detection\\.venv\\Lib\\site-packages\\simpletransformers\\classification\\classification_model.py:2260: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Predicting: 100%|██████████| 39/39 [00:14<00:00,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.txt: 2094 predictions\n",
      "test.txt: 3832 predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load official test set (no labels) and get predictions from best model\n",
    "test_df = pd.read_csv('task4_test.tsv', sep='\\t', header=None,\n",
    "                         names=['par_id', 'art_id', 'keyword', 'country_code', 'text'])\n",
    "test_preds, _ = best_model.predict(test_df.text.tolist())\n",
    "labels2file([[k] for k in test_preds], 'submission/test.txt')\n",
    "print(f'submission/dev.txt: {len(best_preds)} predictions')\n",
    "print(f'submission/test.txt: {len(test_preds)} predictions')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
